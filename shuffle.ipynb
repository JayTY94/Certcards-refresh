{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('certcards2.txt', mode='r', encoding='utf8') as f:\n",
    "    all_cards = f.read()\n",
    "    \n",
    "card_split_pattern = r'\\n\\n\\n\\d+\\n'\n",
    "all_cards = re.split(card_split_pattern, all_cards)\n",
    "# Use re.DOTALL to allow . to match newline characters\n",
    "card_pattern = re.compile(r'(.+?)\\n([\\s\\S]+)', re.DOTALL)\n",
    "cards = [(match.group(1), match.group(2)) for cstring in all_cards if (match := re.search(card_pattern, cstring))]\n",
    "\n",
    "# removing the cards that have no content and trimming\n",
    "cards = [(subject, stripped_content) for subject, content in cards if len(stripped_content := content.strip()) > 5]\n",
    "\n",
    "def hash_string_md5(s):\n",
    "    \"\"\"\n",
    "    Hashes a string using MD5 and returns a truncated hash for efficiency.\n",
    "\n",
    "    Parameters:\n",
    "    - s (str): The input string to hash.\n",
    "\n",
    "    Returns:\n",
    "    - str: The truncated hexadecimal hash string.\n",
    "    \"\"\"\n",
    "    if pd.isnull(s):\n",
    "        return None  # Handle NaN values gracefully\n",
    "    return hashlib.md5(s.encode('utf-8')).hexdigest()  # Truncate to first 12 characters\n",
    "\n",
    "\n",
    "def remake_card_document(existing_cards: pd.DataFrame, filename: str='certcards2.txt'):\n",
    "    with open(filename, mode='w', encoding='utf8') as f:\n",
    "        i = 1\n",
    "        for _, row in existing_cards.iterrows():\n",
    "            print(i)\n",
    "            f.write('\\n'*5)\n",
    "            f.write(str(i)+'\\n')  \n",
    "            f.write(row['head']+'\\n')\n",
    "            f.write(row['body'])\n",
    "            i+=1\n",
    "            # print(F\"{row['head']}: {row['age']:.4f}\")\n",
    "\n",
    "\n",
    "existing_cards = pd.DataFrame(cards, columns=['head', 'body'])\n",
    "\n",
    "\n",
    "# existing_cards['age'] = [random.random() for _ in existing_cards.index]\n",
    "existing_cards['hash'] = existing_cards['body'].apply(hash_string_md5)\n",
    "existing_cards\n",
    "\n",
    "card_ages = pd.read_json('card_ages.json')\n",
    "# found_cards = pd.DataFrame(cards, columns=['head', 'body'])\n",
    "# found_cards['hash'] = found_cards['body'].apply(hash_string_md5)\n",
    "\n",
    "cards_to_age = pd.merge(\n",
    "    left=existing_cards,\n",
    "    right=card_ages[['hash', 'age']],\n",
    "    left_on='hash', right_on='hash',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "cards_to_age['age'] = cards_to_age['age'].fillna(0)\n",
    "cards_to_age['age'] = cards_to_age['age'] * 1.1\n",
    "cards_to_age['age'] = cards_to_age['age'] + [random.random() for _ in cards_to_age.index]\n",
    "\n",
    "cards_to_age = cards_to_age.sort_values('age', ascending=False)\n",
    "cards_to_age.drop_duplicates(subset=['hash'], keep='first')\n",
    "cards_to_age.to_json('card_ages.json', indent=2)\n",
    "\n",
    "existing_cards = cards_to_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>body</th>\n",
       "      <th>hash</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Python</td>\n",
       "      <td>In Python, arithmetic operators are supported ...</td>\n",
       "      <td>c456276e30350cb9fb497d94fd29beb1</td>\n",
       "      <td>14.396696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General</td>\n",
       "      <td>‘L’esprit de l’escalier’ - literally meaning '...</td>\n",
       "      <td>02d12ed8095689928260c6765fa1a47b</td>\n",
       "      <td>14.170537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Azure AI Search</td>\n",
       "      <td>Scalar Quantization: Scalar Quantization reduc...</td>\n",
       "      <td>fdd381f92069b85aa00c179ec7dbf3d5</td>\n",
       "      <td>14.119390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dataverse Queries</td>\n",
       "      <td>Lookup Field\\nDefinition: A special type of fi...</td>\n",
       "      <td>1dd9f8495a55f324f899ad2ec9466a6a</td>\n",
       "      <td>14.017716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Python</td>\n",
       "      <td>In a Python Template string, placeholders cons...</td>\n",
       "      <td>e737d6efc99bcb0672fb4cad93b5b1b1</td>\n",
       "      <td>13.878580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Azure Kubernetes Learning Path</td>\n",
       "      <td>Docker images are large files that are initial...</td>\n",
       "      <td>1f34225dc63efe31fdc902ae0b0e52d8</td>\n",
       "      <td>2.091846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Azure Kubernetes Learning Path</td>\n",
       "      <td>We use Unionfs to create Docker images. Unionf...</td>\n",
       "      <td>6f4f704ff4303008479e6d1aeae01107</td>\n",
       "      <td>2.090260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Azure Kubernetes Learning Path</td>\n",
       "      <td>The ENTRYPOINT in the Dockerfileile indicates ...</td>\n",
       "      <td>ca97bcddbd37e408542d800643d1f1a0</td>\n",
       "      <td>1.933648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>pandas</td>\n",
       "      <td>There is an attribute on a dataframe column to...</td>\n",
       "      <td>6311b73b1509536ad940cd47aacde11b</td>\n",
       "      <td>1.034697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Azure Kubernetes Learning Path</td>\n",
       "      <td>A Dockerfile is a text file that contains the ...</td>\n",
       "      <td>588e821f49d7e56ca83ec511412ee468</td>\n",
       "      <td>0.844047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               head  \\\n",
       "193                          Python   \n",
       "3                           General   \n",
       "352                 Azure AI Search   \n",
       "33                Dataverse Queries   \n",
       "19                           Python   \n",
       "..                              ...   \n",
       "131  Azure Kubernetes Learning Path   \n",
       "171  Azure Kubernetes Learning Path   \n",
       "184  Azure Kubernetes Learning Path   \n",
       "136                          pandas   \n",
       "235  Azure Kubernetes Learning Path   \n",
       "\n",
       "                                                  body  \\\n",
       "193  In Python, arithmetic operators are supported ...   \n",
       "3    ‘L’esprit de l’escalier’ - literally meaning '...   \n",
       "352  Scalar Quantization: Scalar Quantization reduc...   \n",
       "33   Lookup Field\\nDefinition: A special type of fi...   \n",
       "19   In a Python Template string, placeholders cons...   \n",
       "..                                                 ...   \n",
       "131  Docker images are large files that are initial...   \n",
       "171  We use Unionfs to create Docker images. Unionf...   \n",
       "184  The ENTRYPOINT in the Dockerfileile indicates ...   \n",
       "136  There is an attribute on a dataframe column to...   \n",
       "235  A Dockerfile is a text file that contains the ...   \n",
       "\n",
       "                                 hash        age  \n",
       "193  c456276e30350cb9fb497d94fd29beb1  14.396696  \n",
       "3    02d12ed8095689928260c6765fa1a47b  14.170537  \n",
       "352  fdd381f92069b85aa00c179ec7dbf3d5  14.119390  \n",
       "33   1dd9f8495a55f324f899ad2ec9466a6a  14.017716  \n",
       "19   e737d6efc99bcb0672fb4cad93b5b1b1  13.878580  \n",
       "..                                ...        ...  \n",
       "131  1f34225dc63efe31fdc902ae0b0e52d8   2.091846  \n",
       "171  6f4f704ff4303008479e6d1aeae01107   2.090260  \n",
       "184  ca97bcddbd37e408542d800643d1f1a0   1.933648  \n",
       "136  6311b73b1509536ad940cd47aacde11b   1.034697  \n",
       "235  588e821f49d7e56ca83ec511412ee468   0.844047  \n",
       "\n",
       "[356 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completely Random Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows, cols = existing_cards.shape\n",
    "\n",
    "# existing_cards = existing_cards.sample(frac=1)\n",
    "# remake_card_document(filename='certcards2.txt', existing_cards = existing_cards)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "remake_card_document(filename='certcards2.txt', existing_cards=existing_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers with fewest notes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency = existing_cards['head'].value_counts(ascending=True)\n",
    "# print(frequency)\n",
    "\n",
    "# existing_cards = pd.merge(\n",
    "#     left=existing_cards,\n",
    "#     right=frequency.rename('frequency'),\n",
    "#     left_on='head', right_index=True,\n",
    "#     how='left'\n",
    "# )\n",
    "# existing_cards.sort_values(['frequency', 'head'], ascending=True, inplace=True)\n",
    "\n",
    "# remake_card_document(filename='certcards2.txt', existing_cards=existing_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "head\n",
       "Python                            38\n",
       "Diffusers Library                 31\n",
       "Azure Kubernetes Learning Path    19\n",
       "Power BI                          14\n",
       "MS Identity Platform              13\n",
       "sklearn                           12\n",
       "DNS                               12\n",
       "Azure AI Search                   12\n",
       "sklearn                           11\n",
       "Kali Linux                        11\n",
       "Diffusers from Hugging Face       10\n",
       "Azure Functions                   10\n",
       "PP365                              9\n",
       "Azure Functions                    9\n",
       "General                            9\n",
       "AKS                                8\n",
       "Dataverse Queries                  8\n",
       "pandas                             8\n",
       "Workera.ai                         7\n",
       "OData                              7\n",
       "Conditional Access                 7\n",
       "Dataverse Plugins                  7\n",
       "Git                                6\n",
       "UHero Requests                     6\n",
       "Azure Storage                      6\n",
       "Azure OpenAI                       6\n",
       "Dataverse                          6\n",
       "Azure VDI Project                  6\n",
       "Diffusers Documentation            6\n",
       "OData Requests                     5\n",
       "Developer Mode                     4\n",
       "numpy                              4\n",
       "Azure Functions Quickstart         4\n",
       "Kaggle                             4\n",
       "OAuth2.0                           3\n",
       "Maths                              3\n",
       "MS Data Analyst                    3\n",
       "Power Platform                     3\n",
       "RAG                                3\n",
       "Site Scraping                      2\n",
       "Power Platform administration      2\n",
       "Power BI Desktop                   2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_cards['head'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
